import os
from gensim import models
import json
import numpy as np
from keras.models import *
from keras.layers import *

def readJson(filename):
	print "Reading [%s]..." % (filename)
	with open(filename) as inputFile:
		jsonData = json.load(inputFile)
	print "Finished reading [%s]." % (filename)
	return jsonData

word2VecPath = '/sb-personal/cvqa/data/word2vec/google-news/GoogleNews-vectors-negative300.bin'
captionFile = '/sb-personal/cvqa/data/cvqa/imagecaptions.json'
questionsFile = '/sb-personal/cvqa/data/cvqa/cvqa-sameQuestionDataset-subset-list1.json'

maxQuestionLength = 8
maxCaptionLength = 16
wordVectorSize = 300
embeddingSize = 250
numberOfEpochs = 50

# print "Loading Word2Vec Dictionary. This may take a long time..."
# w2v = models.Word2Vec.load_word2vec_format(word2VecPath, binary=True)

print "Loading Captions generated by a Pre-Trained Captioning Model for Images..."
imageCaptions = readJson(captionFile)

print "Loading Questions..."
questionRows = readJson(questionsFile)

questionKeys = questionRows.keys()[:100]

words = {}

for i,questionRowIndex in enumerate(questionKeys):
	questionRow = questionRows[questionRowIndex]
	imageFilename = questionRow['image']
	caption = imageCaptions[imageFilename]

	questionWords = questionRow['question'].split(' ')
	captionWords = caption.split(' ')

	for w in questionWords:
		words[w] = 1
	
	for w in captionWords:
		words[w] = 1

	maxQuestionLength = max(maxQuestionLength, len(questionWords))
	maxCaptionLength = max(maxCaptionLength, len(captionWords))

words = words.keys()

vocabSize = len(words) + 1
totalFeatureLength = maxQuestionLength + maxCaptionLength

print 'Total Question Rows: [%d]' % (len(questionRows))
print len(questionKeys)
print maxQuestionLength
print maxCaptionLength
print vocabSize

word_index = {}
index_word = {}

for i, word in enumerate(words):
    word_index[word] = i + 1
    index_word[i + 1] = word

X = []
X_cap = []
X_ques = []
y = []

maxLength = max(maxQuestionLength, maxCaptionLength)

for i,questionRowIndex in enumerate(questionKeys):
	questionRow = questionRows[questionRowIndex]
	imageFilename = questionRow['image']
	caption = imageCaptions[imageFilename]

	labels = [int(l) for l in questionRow['wordLabels'].split(' ')]
	questionWords = questionRow['question'].split(' ')
	captioNWords = caption.split(' ')

	# print captionWords
	# print questionWords
	# print labels

	for currentWi in range(len(questionWords)):
		captionFeature = np.zeros(maxLength)
		questionFeature = np.zeros(maxLength)

		feature = np.zeros(totalFeatureLength)
		for ci,c in enumerate(captionWords):
			feature[ci] = word_index[c]
			captionFeature[ci] = word_index[c]

		for wi in range(0,currentWi+1):
			feature[wi+maxCaptionLength] = word_index[questionWords[wi]]
			questionFeature[wi] = word_index[questionWords[wi]]

		X_cap.append(captionFeature)
		X_ques.append(questionFeature)
		X.append(feature)
		y.append(labels[currentWi])

cutoff = len(X)/2
X_cap_train = np.asarray(X_cap[:cutoff])
X_cap_test = np.asarray(X_cap[cutoff:])

X_train = np.asarray(X[:cutoff])
X_test = np.asarray(X[cutoff:])
y_train = np.asarray(y[:cutoff])
y_test = np.asarray(y[cutoff:])

print len(X)
print len(X_train)

# encoder_a = Sequential()
# encoder_a.add(LSTM(40, input_shape=(timesteps,data_dim)))
# #encoder_a.add(LSTM(40))

# encoder_b = Sequential()
# encoder_b.add(LSTM(40, input_shape=(timesteps,data_dim)))

model = Sequential()
model.add(Embedding(vocabSize, 256, input_length=totalFeatureLength, mask_zero=False))
model.add(GRU(output_dim=embeddingSize, return_sequences=False))
model.add(Dense(40, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy', 'fmeasure', 'precision', 'recall'])

print(model.summary())
print(model.get_config())

model.fit(X_train,y_train, nb_epoch=numberOfEpochs, validation_split=0.2)

pred=model.predict_proba(X_test)
