import sys
import argparse
import pandas as pd
import json
import os
import time

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

from models import *
from featureExtractors import *

def readJson(filename):
	print "Reading [%s]..." % (filename)
	with open(os.path.join(filename)) as inputFile:
		jsonData = json.load(inputFile)
	print "Finished reading [%s]." % (filename)
	return jsonData

def saveStats(stats,filePath):
	print 'Outputting results to [%s]...' % (filePath)
	with open(filePath, 'w') as outputFile:
		outputFile.write(json.dumps(stats))
	print 'Finished outputting results to [%s]' % (filePath)

def stats(pred, gt, pred_n, gt_n):
	stats = {}
	#	print accuracy_score(gt,pred)
	stats['True Premise Recall'] = recall_score(gt,pred)
	stats['True Premise Precision'] = precision_score(gt,pred)
	stats['False Premise Recall'] = recall_score(gt_n,pred_n)
	stats['False Premise Precision'] = precision_score(gt_n,pred_n)
	stats['Normalized Accuracy'] = (recall_score(gt,pred)+recall_score(gt_n,pred_n))/2

	print "Relevant Class Recall: "+str(recall_score(gt,pred))
	print "Relevant Class Precision: "+str(precision_score(gt,pred))

	#	print accuracy_score(gt_n,pred_n)
	print "Irrelevant Class Recall: "+str(recall_score(gt_n,pred_n))
	print "Irrelevant Class Precision: "+str(precision_score(gt_n,pred_n))
	print "Normalized Acc: mean(Recall_Relevant_Class, Recall_Irrelevant_Class) : "
	print (recall_score(gt,pred)+recall_score(gt_n,pred_n))/2

	return stats

def parse_args():
	parser= argparse.ArgumentParser(description='Train/Test CVQA Models')
	parser.add_argument('-m','--model', help='Use lstm for LSTM model, avgw2v for average word2vec model')
	parser.add_argument('-w','--word2VecPath', help='Word2Vec model file')
	parser.add_argument('-x','--captionFile', help='Input caption file')
	parser.add_argument('-q','--questionsFile', help='Input questions file')
	parser.add_argument('-n','--windowSize', help='Window size to use when splitting sentences',type=int)
	parser.add_argument('-r','--outputResultsDir', help='Results output dir')
	parser.add_argument('-e','--numberOfEpochs', help='Number of epochs for training',type=int)
	parser.add_argument('-l','--maxQuestionLength', help='Max number of words in a question',type=int, default=20)
	parser.add_argument('--times', dest='times', help='Number of times to run test/train splits', default=40, type=int)

	if len(sys.argv) ==1:
		parser.print_help()
		sys.exit(1)

	args=parser.parse_args()
	return args

def split(data):
	X = data['X']
	X_cap = data['X_cap']
	y = data['y']
	outputs = data['outputs']

	X_train, X_test, X_cap_train, X_cap_test, y_train, y_test, outputs_train, outputs_test = train_test_split(X, X_cap, y, outputs, test_size=0.333333)

	train = {}
	test = {}

	train['X'] = np.asarray(X_train)
	train['X_cap'] = np.asarray(X_cap_train)
	train['y'] = np.asarray(y_train)
	train['outputs'] = outputs_train
	
	test['X'] = np.asarray(X_test)
	test['X_cap'] = np.asarray(X_cap_test)
	test['y'] = np.asarray(y_test)
	test['outputs'] = outputs_test

	return train, test


if __name__=='__main__':
	args = parse_args()
	tic = time.time()

	modelNames = args.model.split(',')
	modelCreators = []
	for m in modelNames:
		if (m == 'lstm'):
			modelCreator = LSTMModel()
			featureExtractor = W2VFeatureExtractor(args)
		elif(m == 'questionOnly'):
			modelCreator = QuestionOnlyLSTMModel()
			featureExtractor = W2VFeatureExtractor(args)
		elif(m == 'avgw2v'):
			modelCreator = MLP(300 * 2)
			featureExtractor = AverageFeatureExtractor(args)
		elif(m == 'wmdw2v'):
			modelCreator = MLP(args.windowSize)
			featureExtractor = WMDistanceFeatureExtractor(args)
		elif(m == 'random'):
			modelCreator = RandomModel()
			featureExtractor = W2VFeatureExtractor(args)

		modelCreators.append({'modelName':m,'modelCreator':modelCreator,'featureExtractor':featureExtractor})

	print "Loading Captions generated by a Pre-Trained Captioning Model for Images..."
	image_captions = readJson(args.captionFile)

	print "Loading Questions..."
	questions = readJson(args.questionsFile)

	print "Extracting Features ... " 
	featureExtractor = modelCreators[0]['featureExtractor']
	data = featureExtractor.extractFeatures(questions, image_captions, args)

	for attempt in range(0,args.times):

		train,test = split(data)

		for m in modelCreators:
			modelCreator = m['modelCreator']
			modelName = m['modelName']
			model=modelCreator.train(args, train)	

			print "Testing on Train..."
			pred,gt,pred_n,gt_n,pred_train=modelCreator.test(train ,model)

			for i,o in enumerate(train['outputs']):
				o['predicted'] = str(pred_train[i][0])

			outputStats = {}
			outputStats['train'] = stats(pred,gt,pred_n,gt_n)	

			print "Testing on Test..."
			pred,gt,pred_n,gt_n,pred_test=modelCreator.test(test ,model)	
			outputStats['test'] = stats(pred,gt,pred_n,gt_n)

			for i,o in enumerate(test['outputs']):
				o['predicted'] = str(pred_test[i][0])
			
			pd.DataFrame(train['outputs']).to_csv(os.path.join(args.outputResultsDir, '%s-%d-train.csv' % (modelName,attempt)))
			pd.DataFrame(test['outputs']).to_csv(os.path.join(args.outputResultsDir, '%s-%d-test.csv' % (modelName,attempt)))

			saveStats(outputStats, os.path.join(args.outputResultsDir, '%s-%d-stats.json' % (modelName,attempt)))
	print 'Finished in (t=%0.2fs)'%(time.time()- tic)
