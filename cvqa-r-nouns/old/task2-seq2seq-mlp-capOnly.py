import os
from gensim import models
import json
import numpy as np
from keras.models import *
from keras.layers import *
import keras
from sklearn.metrics import *
import keras.backend as K
import pandas as pd

def readJson(filename):
	print "Reading [%s]..." % (filename)
	with open(filename) as inputFile:
		jsonData = json.load(inputFile)
	print "Finished reading [%s]." % (filename)
	return jsonData

def extractFeatures(questionRows, totalLength, maxLength):
	questionKeys = questionRows.keys()

	print 'Total Question Rows: [%d]' % (len(questionRows))
	print 'Filtered Question Rows: [%d]' % (len(questionKeys))

	X_captions = []
	x_questions = []
	y = []

	print 'Max Sequence Length: [%d]' % (maxLength)
	print 'Total Sequence Length: [%d]' % (totalLength)

	for i,questionRowIndex in enumerate(questionKeys):
		questionRow = questionRows[questionRowIndex]
		imageFilename = questionRow['image']
		caption = imageCaptions[imageFilename]

		labels = [int(l) for l in questionRow['wordLabels'].split(' ')]
		questionWords = questionRow['question'].split(' ')
		captionWords = caption.split(' ')

		newLabels = []
		newQuestionWords = []
		newCaptionWords = []
		for wi, w in enumerate(questionWords):
			if w in w2v:
				if w.lower() not in excludeWordList:
					newQuestionWords.append(w)
					newLabels.append(labels[wi])
		for w in captionWords:
			if w in w2v:
				if w.lower() not in excludeWordList:
					newCaptionWords.append(w)

		labels = newLabels
		questionWords = newQuestionWords
		captionWords = newCaptionWords

		captionFeature = np.zeros((maxLength, wordVectorSize))
		questionFeature = np.zeros((maxLength, wordVectorSize))
		labelFeature = np.zeros(len(word_index))

		relevant = True
		for li,l in enumerate(labels):
			if (l == 0):
				labelFeature[word_index[questionWords[li]]] = 1
				relevant = False

		if relevant:
			labelFeature[0] = 1
		
		for ci,c in enumerate(captionWords):
			captionFeature[ci] = w2v[c]

		for ci,c in enumerate(questionWords):
			questionFeature[ci] = w2v[c]

		X_captions.append(captionFeature)
		x_questions.append(questionFeature)
		y.append(labelFeature)

	return np.asarray(x_questions),np.asarray(X_captions),np.asarray(y)

def extractVocab(rowSet):
	word_index = {'RELEVANT':0}
	index_word = {0:'RELEVANT'}
	for r in rowSet:
		for i,questionRowIndex in enumerate(r):
			questionRow = r[questionRowIndex]
			imageFilename = questionRow['image']
			caption = imageCaptions[imageFilename]

			questionWords = questionRow['question'].split(' ')
			for w in questionWords:
				if (w in w2v) and (w not in word_index) and (w not in excludeWordList):
					word_index[w] = len(word_index)
					index_word[word_index[w]] = w
			captionWords = caption.split(' ')
			for w in captionWords:
				if (w in w2v) and (w not in word_index) and (w not in excludeWordList):
					word_index[w] = len(word_index)
					index_word[word_index[w]] = w

	return word_index, index_word


word2VecPath = '/sb-personal/cvqa/data/word2vec/google-news/GoogleNews-vectors-negative300.bin'
captionFile = '/sb-personal/cvqa/data/cvqa/imagecaptions.json'
trainFile = '/sb-personal/cvqa/data/cvqa/cvqa-sameQuestionDataset-subset-list3-train.json'
testFile = '/sb-personal/cvqa/data/cvqa/cvqa-sameQuestionDataset-subset-list3-test.json'

maxQuestionLength = 8
maxCaptionLength = 16
wordVectorSize = 300
embeddingSize = 250
numberOfEpochs = 10
subsetCount = 4000
maxLength = 20
totalLength = maxLength * 2
# totalLength = maxLength
n_hidden = 40
excludeWordList = ['is','a','the','what','that','to','who','why']

print "Loading Word2Vec Dictionary. This may take a long time..."
w2v = models.Word2Vec.load_word2vec_format(word2VecPath, binary=True)

print "Loading Captions generated by a Pre-Trained Captioning Model for Images..."
imageCaptions = readJson(captionFile)

print "Loading Questions..."

trainRows = readJson(trainFile)
testRows = readJson(testFile)

word_index, index_word = extractVocab([trainRows, testRows])

print len(word_index)

X_questions_train, X_captions_train, y_train = extractFeatures(trainRows, totalLength, maxLength)
X_questions_test, X_captions_test, y_test = extractFeatures(testRows, totalLength, maxLength)

print 'Total data samples: [%d]' % (len(y_train) + len(y_test))
print '\tTraining data size: [%d]' % (len(y_train))
print '\tTest data size: [%d]' % (len(y_test))

encoder_a = Sequential()
encoder_a.add(LSTM(40, input_shape=(maxLength,wordVectorSize)))

# encoder_b = Sequential()
# encoder_b.add(LSTM(40, input_shape=(maxLength,wordVectorSize)))

decoder = Sequential()
# decoder.add(Merge([encoder_a, encoder_b], mode='concat'))
decoder.add(encoder_a)
decoder.add(Dense(40, activation='relu'))
decoder.add(Dense(15, activation='relu'))
decoder.add(Dense(len(word_index), activation='softmax'))
decoder.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy', 'precision','recall','fmeasure'])

print(decoder.summary())
print(decoder.get_config())

decoder.fit(X_captions_train,y_train, nb_epoch=numberOfEpochs, verbose=1)

names = decoder.metrics_names
scores = decoder.test_on_batch(X_captions_test, y_test)
print dict(zip(names, scores))
# y_predict = decoder.predict_proba(X_test, verbose=0)
# # print 'Before'
# # print y_predict
# for value in np.nditer(y_predict, op_flags=['readwrite']):
# 	if value > 0.15:
# 		value[...] = 1
# 	else:
# 		value[...] = 0
# # print 'After'
# # print y_predict

# y_predict = np.reshape(y_predict,(len(y_test),totalLength))
# y_test = np.reshape(y_test,(len(y_test),totalLength))
# # print 'Recall: [%f]' % (recall_score(y_test,y_predict))
# # print 'Precision: [%f]' % (precision_score(y_test,y_predict))
# print 'Accuracy: [%f]' % (accuracy_score(y_test,y_predict))

# totals = []
# for p,_ in enumerate(y_predict):
# 	totals.append({'predict':np.array_str(y_predict[p]), 'actual':np.array_str(y_test[p])})

# outputFile = '/sb-personal/cvqa/data/cvqa/output.csv'
# pd.DataFrame(totals).to_csv(outputFile)